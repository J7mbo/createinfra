# 01. Terraform Nodes

### Topics

- Docker, Docker Compose
- Terraform
- Configuration via Environment Variables
- Makefiles
- Spinning up and down nodes on DigitalOcean


### Pre-requisites

- Docker, docker-compose


### Introduction

So you've built an application, but you need to actually get it "on the internet". We'll need servers or nodes for this, or in DigitalOcean terminology, "droplets".

We can either spin up a server ourselves manually using the browser, choosing relevant settings etc., or we can do it using 'infrastructure as code', which is just a tool reading a configuration file we fill in which then calls API endpoints for us to spin up servers. In our example, DigitalOcean, and the tool is Terraform.

In the future we will be calling terraform from an ansible playbook, but for now we'll start with terraform.

### Configuration with environment variables

Env vars contain our configuration. In the future we'll use docker secrets to store these. For now, copy `.env.template` to `.env` and fill in the values.

### Docker + Terraform

Terraform is available in a docker container so that you don't have to install it locally, so this is added in [docker-compose.yml](../docker-compose.yml). The container runs what it is told to and then exits. If no command is given, it will print the terraform help and exit.

The initially empty [infra/terraform](../infra/terraform) directory is mounted in the container because Terraform will create it's lockfile and state files, and they will be placed in this directory. The container will then exit. Subsequent terraform commands that spin up the container and then exit will also have this directory mounted and so will use the lock file to do their thing. These lock and state files are ignored in `.gitignore` here, but in your actual project, you should [commit the lock file](https://stackoverflow.com/questions/67963719/should-terraform-lock-hcl-be-included-in-the-gitignore-file) and [git ignore the state file](https://stackoverflow.com/questions/38486335/should-i-commit-tfstate-files-to-git).

In this example, Terraform is configured with three `.tf` files (for a clean separation of concerns), which it treats as one file when run within the directory. These files are:

##### [inputs.tf](../infra/terraform/inputs.tf)

Contains what will be user-provided variables to be used by the Terraform Language in the other `.tf` files. If you run Terraform without providing these variables, it will ask for them one-by-one with an interactive prompt.

These variables can be populated from environment variables, but the environment variables must pre-fixed with `TF_VAR`. You can see us passing these in via [docker-compose.yml](../docker-compose.yml) under the `environment` key. The terraform docker-compose service has the `env_file` key to use our `.env` file for it's source of variables.

Thus we go from `.env` --> `docker-compose.yml` (all prefixed with `TF_VAR`) --> `inputs.tf` using these environment variables as values --> Terraform using the values from `inputs.tf`.

#### [droplets.tf](../infra/terraform/droplets.tf)

Contains an array of nodes/servers/droplets to be spun up on DigitalOcean. Initially this is only one node, however the `digitalocean_droplet.droplets` key beneath uses `for_each` to loop around any nodes we place in this array, making it easy to add a new node by adding the configuration (via `inputs.tf` and environment variables) for it and then placing it in this array.

#### [digitalocean.tf](../infra/terraform/digitalocean.tf)

Contains the main DigitalOcean config which sets the name of the project, the fact that we are using the [digitalocean/digitalocean provider](https://registry.terraform.io/providers/digitalocean/digitalocean/latest/docs), and our access token. This file uses droplets from `droplets.tf` to say "these are the droplets we are working with" via the `resources` key.   

Terraform provides us with four commands that we care about here:

- `terraform init`, which sets everything up for us and creates it's needed directories, lock / state files.
- `terraform plan`, which shows what would happen if we ran apply, but doesn't actually run that provisioning yet.
- `terraform apply`, which applies the configuration we have and provisions the node we have asked for on DigitalOcean.
- `terraform destroy`, which looks at the configuration and deletes the resources that should have been created by it.

Terraform is being run in a docker container though, and you have to pass "commands" like `plan` and `apply` to it via the `command` key in [docker-compose.yml](../docker-compose.yml). Because these commands will change depending on what we want to do, this is set as an environment variable with the key `TERRAFORM_COMMAND`, and the final piece of the puzzle is we create shortcuts, or "targets" for these, inside a [Makefile](../Makefile).

### Makefile

The [Makefile](../Makefile) will handle the shortcuts (targets) to the commands that we are running so that you don't need to remember terraform commands.

It contains a `help` target that parses the Makefile itself to print out available commands and their descriptions. Try `make help`. I use this part in every project that has a Makefile.

You'll see that there is an `--init` target. Prefixing a target with `--` is a gnu make convention for "private" targets, i.e. targets that you want other targets to use, but you don't want them to be advertised as something you should use directly. `--init` is used by both `plan` and `apply` to make sure that we've run it already, so you don't need to remember to run it for the first time.

### Using this

- Make sure docker is running and you have `docker-compose` installed
- Copy `.env.template` to `.env` and fill in the configuration values
- Run `make plan` and see how two resources would be created via DigitalOcean's API, via Terraform - a project and a droplet
- Run `make provision`, wait until it's finished, and go look at the DigitalOcean UI to see your new project containing a droplet
- Run `make destroy`, wait until it's finished, and see how your project and associated droplet in the DigitalOcean UI are gone (not paying for them anymore, you're free!)

### Next up

Automating SSH keys so that you can SSH into the nodes you spin up, and installing docker on the nodes themselves so that we can eventually create a swarm with docker swarm and deploy docker containers to them. Fun stuff coming up!